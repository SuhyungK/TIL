# 24_Start

## 목차

- SW 문제 해결
- 복잡도 분석
- 표준 입출력 방법
- 비트 연산
- 진수
- 실수

### 학습목표

- 효율적인 알고리즘의 필요성을 이해하고 알고리즘의 성능 측정 방법 중 하나인 시간 복잡도에 대해 이해한다.
- 비트 수준의 연산과 알고리즘에 대해 이해
- 실수 표현 방법에 대해 이해

## 프로그래밍하기 위한 제약 조건과 요구사항

- 프로그래밍 언어의 특성
- HW와 OS에 관한 지식
- 라이브러리들의 유의 사항들
- 프로그램이 사용할 수 있는 최대 메모리
- 사용자 대응 시간 제한
- 재사용성이 높은 간결한 코드

## SW 문제 해결 역량

- 언어 라이브러리 자료구조 알고리즘에 대한 지식을 연결하여 큰 그림을 만드는 능력
- 일부 언어 프레임워크 개발 방법을 배워나가는 것만은 충분하지 않다 → 조합할 줄 알아야 함
- 경험을 통해서 막연히 나아지리라 짐작하지만 항상 그런 경험이 주어지는 것은 아님

### 문제 해결 과정

1. 문제를 읽고 이해
2. 익숙한 용어로 재정의
3. 어떻게 해결할지 계획 세운다
4. 계획 검증
5. 프로그램으로 구현
6. 어떻게 풀었는지 돌아보고, 개선할 방법 찾기

### 문제 해결 전략

- 직관과 체계적 접근

### 체계적 접근을 위한 질문들

- 비슷한 문제를 풀어본 적이 있던가?
- 단순한 방법에서 시작할 수 있을까?
- 문제를 단순화 할 수 있을까? → 불필요한 부분 제거
- 그림으로 그려 볼 수 있을까?
- 수식으로 표현할 수 있을까?
- 문제를 분해할 수 있을까?
- 뒤에서부터 생각해서 문제를 풀 수 있을까?

## 알고리즘

- 유한한 단계를 통해 문제를 해결하기 위한 절차나 방법
- 컴퓨터가 어떤 일을 수행하기 위한 단계적 방법

- 공간적 효율성과 시간적 효율성
    - 공간적 효율성 : 메모리 공간
    - 시간적 효율성 : 시간
- 효율성을 뒤집어 표현하면 복잡도(Complexity)가 된다. 복잡도가 높을수록 효율성은 저하

### 알고리즘의 효율

- 시간적 복잡도 분석
    - 하드웨어 환경에 따라 처리시간 다름
    - 부동 소수 처리 프로세서 존재 유무
        - CPU 안의 정수와 소수 처리 하는 부분이 내부적으로 분리되어 있음
    - 소프트웨어 환경에 따라 처리 시간 다름
        - 프로그램 언어의 종류
        - 운영체제, 컴파일러의 종류
        

## 복잡도의 점근적 표기

- 시간 (또는 공간)복잡도는 입력 크기에 대한 (연산량의)함수로 표기
- 주로 여러 개의 항을 가지는 다항식
    - $T(n+1) = T(n) + 1$
- 이를 단순한 함수로 표현하기 위해 점근적 표기(*Asymptotic Notation)* 사용
- 입력 크기 n이 무한대로 커질 때 복잡도를 간단히 표현하기 위해 사용하는 표기법
    - O(Big-Oh)- 표기

### O(Big-Oh)-표기

- O-표기는 복잡도의 **점근적 상한**
    - 연산량 최악의 경우에도 여기는 넘어가지 않는다는 상한선
- 복잡도가 $f(n) = 2n^2 - 7n + 4$ 라면 f(n)의 O 표기는 $O(n^2)$
- $f(n)$ 의 단순화된 표현은 $n^2$
- ⇒ 단순히 실행시간이 $n^2$ 에 비례하는 알고리즘
- 단순화된 함수 $n^2$에 임의의 상수 c를 곱한 $cn^2$이 n이 증가함에 따라 $f(n)$의 상한이 된다.

### $Ω$ (Big-Omega)표기

- 복잡도의 **점근적 하한**
    - 최선의 경우(아무리 잘해도) 이만한 시간은 걸린다
- $f(n) = 2n^2 - 7n + 4$ 의 **Ω** 표기는 $Ω(n^2)$
- $f(n)=Ω(n^2)$은 n이 증가함에 따라 $2n^2-7n+4$이 $cn^2$보다 작을 수는 없다. 이때 c = 1 로 놓으면 된다.

### **Θ(Theta) 표기**

- 빅오 표기와 오메가 표기가 같은 경우
- $f(n)$이 증가함에 따라 $n^2$과 동일한 증가율을 가진다 ⇒ 항상 이 정도의 연산은 발생함

## 자주 사용하는 O-표기

- $O(1)$ 상수 시간
- $O(logn)$ 로그(대수)시간
- $O(n)$ 선형 시간
- $O(nlogn)$ 로그 선형 시간
- $O(n^2)$ 제곱 시간
- $O(n^3)$ 세제곱 시간
- $O(2^n)$ 지수 시간

## 효율적인 알고리즘이 필요한 이유?

- 10억 개의 숫자를 정렬하는데 $O(n^2)$ 알고리즘은 300여년 걸리는 반면에 $O(nlogn)$ 알고리즘은 5분 만에 정렬함
- 값비싼 하드웨어 개발보다 효율적 알고리즘 개발이 훨씬 더 경제적

## 비트 연산

![Untitled](images/09_%EB%B9%84%ED%8A%B8%EC%97%B0%EC%82%B0.png)

- 같은 자리의 비트끼리만 비교
    - 덧셈에서 자리수가 올라가는 경우는 없음
- AND (&)
    - *bit*  & 0 ⇒ 무조건 0
    - *bit* & 1 ⇒ 원래 *bit* 그대로
    - ***“특정 bit를 0으로 만들 때”***
    - *“비트 검사”*
- OR ( | )
    - *bit* | O ⇒ 원래 *bit* 그대로
    - *bit* | 1 ⇒ ***특정 bit 1로 만들 때***
- *1 << n*
    - $2^n$의 값을 갖는다
    - 원소가 $n$개일 경우 모든 부분집합의 수
    - *Power set*
        - 공집합과 자기 자신을 포함한 모든 부분집합
        - 각 원소가 포함되거나 *or* 포함되지 않는 2가지 경우의 수를 계산하면 모든 부분집합의 수가 계산됨
- *i & ( 1 << j )*
    - ***i*의 *j*번 비트 검사**
    - *i*의 *j*번째 비트가 1인지 아닌지 검사
    

### 비트 연산 예제1

- 10진수의 수 → 2진수 변환 :  *j*번째 자리의 수가 1이면 1을, 0이면 0을 출력하는 방식

```python
def Bbit_print(i):
    output = ''
    for j in range(7, -1, -1):
        output += "1" if i & (1 << j) else "0"
    print(output)

for i in range(-5, 6):
    print("%3d = " % i, end='')
    Bbit_print(i)

"""
 -5 = 11111011
 -4 = 11111100
 -3 = 11111101
 -2 = 11111110
 -1 = 11111111
  0 = 00000000
  1 = 00000001
  2 = 00000010
  3 = 00000011
  4 = 00000100
  5 = 00000101
"""
```

### 비트 연산 예제2

- 16진수 한 자리 → 2진수 4자리
- 16진수 두 자리 → 2진수 8자리 ⇒ **8bit = 1byte**
- *0x → 16진수*

```python
def Bbit_print(i):
    output = ''
    for j in range(7, -1, -1):
        output += "1" if i & (1 << j) else "0"
    print(output, end=' ')

a = 0x10
x = 0x01020304
print("%d = " % a, end='')
Bbit_print(a)
print()
print("0%X = " % x, end='')
for i in range(0, 4):
    Bbit_print((x >> i * 8) & 0xff)

"""
16 = 00010000 
01020304 = 00000100 00000011 00000010 00000001
"""
```

## 엔디안(Endianness)

- 컴퓨터의 메모리와 같은 1차원의 공간에 여러 개의 연속된 대상을 배열하는 방법
    - 빅 엔디안 : 큰 단위가 앞에 나옴 *ex) 네트워크*
    - 리틀 엔디안 : 작은 단위가 앞에 나옴 *ex) 대다수 데스크탑 컴퓨터*

```python
# 엔디안 확인 코드

import sys
print(sys.byteorder)
```

### 비트 연산 예제4

```python
def ce1(n):
    return (n << 24 & 0xff000000) | (n << 8 & 0xff000) | (n >> 8 & 0xff00) | (n >> 24 & 0xff)

x = 0x01020304
```

## 진수

- 2진수, 8진수, 10진수, 16진수
- 10진수 → 타 진수로 변환
    - 원하는 타진법의 수로 나눈 뒤 나머지를 거꾸로 읽음

### 음의 정수 표현

- 1의 보수 : 부호와 절대값으로 표현된 값을 부호 비트를 제외한 나머지 비트들을 0은 1로, 1은 0으로 변환
- 2의 보수 : 1의 보수 방법으로 표현된 값의 최하위 비트에 1을 더함

## 실수

- 컴퓨터는 실수를 표현하기 위해 부동 소수점(*floating-point)*표기법
- 부동 소수점 표기 방법은 소수점의 위치를 고정시켜 표현하는 방식
    - 소수 점의 위치를 왼쪽의 가장 유효한 숫자 다음으로 고정시키고 밑수의 지수승으로 표현
    - 1001.0011 → 1.0010011 x $2^3$

### 실수 저장하기 위한 형식

- 단정도 실수(32비트)
    - 부호 1비트 + 지수 8비트 + 가수 32비트
- 배정도 실수
    - 부호 1비트 + 지수 11비트 + 가수 52비트
- 가수부(*mantissa)* : 실수의 유효 자릿수들을 부호화 된 고정 소수점으로 표현한 것
- 지수부(*exponent) :* 실제 소수점의 위치를 지수 승으로 표현

### 단정도 실수 만들기

- 가수 부분 만들기
    - 정수부의 첫 번째 자리가 1이 되도록 오른쪽으로 시프트
    - 소수점 이하를 23비트로 만듦
    - 소수점 이하만을 가수 부분에 저장
    - 지수 부분은 시프트 한 자릿수 만큼 증가 또는 감소
- 지수 부분 만들기
    - 지수부에는 8비트가 배정
    - 숫자로는0~255까지 나타낼 수 있지만, 음수 값을 나타낼 수 있어야 하므로 익세스(*excess)* 표현법 사용
        - 지수부의 값을 반으로 나누어 그 값을 0으로 간주 한 뒤, 그 값을 기준으로 음수 지수 양수 지수를 표현하는 방식

### 컴퓨터의 실수 인식 방식

- 이진법으로 표현 할 수 없는 형태의 실수는 정확한 값이 아니라 근사 값으로 저장되는데 이때 생기는 작은 오차가 계산 과정에서 다른 결과를 가져오게 됨
- 파이썬에서는 내부적으로 더 많은 비트를 사용해서 훨씬 넓은 범위의 실수 표현 가능